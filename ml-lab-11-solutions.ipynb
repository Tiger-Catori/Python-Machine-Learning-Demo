{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Lab 11 \"solutions\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T12:54:17.536000Z",
     "start_time": "2021-12-07T12:54:16.998265Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepallength</th>\n",
       "      <th>sepalwidth</th>\n",
       "      <th>petallength</th>\n",
       "      <th>petalwidth</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepallength  sepalwidth  petallength  petalwidth        class\n",
       "0          5.1         3.5          1.4         0.2  Iris-setosa\n",
       "1          4.9         3.0          1.4         0.2  Iris-setosa\n",
       "2          4.7         3.2          1.3         0.2  Iris-setosa\n",
       "3          4.6         3.1          1.5         0.2  Iris-setosa\n",
       "4          5.0         3.6          1.4         0.2  Iris-setosa"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "import numpy as np\n",
    "\n",
    "iris_data = arff.loadarff('data/iris.arff')\n",
    "iris_df = pd.DataFrame(iris_data[0]) # creates a DataFrame instance\n",
    "iris_df['class'] = iris_df['class'].str.decode('utf-8') # fixes byte strings, avoiding strings like b'Iris-versicolor'\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T12:54:18.040488Z",
     "start_time": "2021-12-07T12:54:17.538353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   sepallength  150 non-null    float64\n",
      " 1   sepalwidth   150 non-null    float64\n",
      " 2   petallength  150 non-null    float64\n",
      " 3   petalwidth   150 non-null    float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 4.8 KB\n",
      "None\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "X = iris_df.iloc[:,:4] # the first 4 columns (and all rows!)\n",
    "y = iris_df.iloc[:,4]  # the last column (and all rows!)\n",
    "\n",
    "y.unique()\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.fit(y.unique())\n",
    "y = label_encoder.transform(y)\n",
    "# y # should now be an array of 0, 1, 2 values\n",
    "\n",
    "print(X.info())\n",
    "print()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T12:54:18.052603Z",
     "start_time": "2021-12-07T12:54:18.042769Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "normalizer = Normalizer()\n",
    "normalizer.fit(X)\n",
    "X_normalised = normalizer.transform(X)\n",
    "# X_normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T12:54:18.063160Z",
     "start_time": "2021-12-07T12:54:18.055796Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "# X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP with hold-out validation\n",
    "\n",
    "3-layer MLP with 10 neurons in the hidden layer. All other hyper-parameters as per default values.\n",
    "\n",
    "Using the normalised feature values here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T12:54:18.174152Z",
     "start_time": "2021-12-07T12:54:18.065511Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8222222222222222\n",
      "\n",
      " [[15  0  0]\n",
      " [ 3  7  5]\n",
      " [ 0  0 15]]\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        15\n",
      "           1       1.00      0.47      0.64        15\n",
      "           2       0.75      1.00      0.86        15\n",
      "\n",
      "    accuracy                           0.82        45\n",
      "   macro avg       0.86      0.82      0.80        45\n",
      "weighted avg       0.86      0.82      0.80        45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalised, y, test_size=0.3, random_state=None, stratify=y)\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes=(10))\n",
    "model = model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"\\n\", metrics.confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n\", metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have seen warnings about the MLP not having converged above, and a rather sub-optimal performance!\n",
    "\n",
    "So, let's see what the performance is like by just increasing the number of training iterations (epochs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T12:54:18.864479Z",
     "start_time": "2021-12-07T12:54:18.175758Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 1.0\n",
      "\n",
      " [[15  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  0 15]]\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      1.00      1.00        15\n",
      "           2       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalised, y, test_size=0.3, random_state=None, stratify=y)\n",
    "\n",
    "epochs = 3000\n",
    "model = MLPClassifier(hidden_layer_sizes=(10), max_iter=epochs)\n",
    "model = model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"\\n\", metrics.confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n\", metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalised vs Scaled feature values\n",
    "\n",
    "Since the Iris dataset is quite a small and simple one, let's let's use cross-validation on the wine dataset to compare performance of the MLP with normalised vs scaled feature values.\n",
    "\n",
    "### Loading and preparing the wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T12:54:18.896032Z",
     "start_time": "2021-12-07T12:54:18.866078Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Loading the dataset\n",
    "dataset = load_wine()\n",
    "\n",
    "# Get the X (feature matrix) and y (class label vector) from the data\n",
    "X, y = dataset.data, dataset.target\n",
    "\n",
    "# Normalising feature matrix\n",
    "normalizer = Normalizer()\n",
    "normalizer.fit(X)\n",
    "X_normalised = normalizer.transform(X)\n",
    "\n",
    "# Scaling feature matrix\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalised feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T12:54:25.020203Z",
     "start_time": "2021-12-07T12:54:18.897278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:          0.92 (+/- 0.11)\n",
      "Training time (s): 1.22 (+/- 0.25)\n",
      "Testing time (s):  0.00 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "epochs = 5000\n",
    "model = MLPClassifier(hidden_layer_sizes=(50), max_iter=epochs)\n",
    "\n",
    "scores = cross_validate(model, X_normalised, y, cv=5)\n",
    "print(\"Accuracy:          %0.2f (+/- %0.2f)\" % (scores['test_score'].mean(), scores['test_score'].std() * 2))\n",
    "print(\"Training time (s): %0.2f (+/- %0.2f)\" % (scores['fit_time'].mean(), scores['fit_time'].std() * 2))\n",
    "print(\"Testing time (s):  %0.2f (+/- %0.2f)\" % (scores['score_time'].mean(), scores['score_time'].std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T12:54:25.902774Z",
     "start_time": "2021-12-07T12:54:25.022101Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:          0.98 (+/- 0.04)\n",
      "Training time (s): 0.17 (+/- 0.03)\n",
      "Testing time (s):  0.00 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "epochs = 5000\n",
    "model = MLPClassifier(hidden_layer_sizes=(30), max_iter=epochs)\n",
    "\n",
    "scores = cross_validate(model, X_scaled, y, cv=5)\n",
    "print(\"Accuracy:          %0.2f (+/- %0.2f)\" % (scores['test_score'].mean(), scores['test_score'].std() * 2))\n",
    "print(\"Training time (s): %0.2f (+/- %0.2f)\" % (scores['fit_time'].mean(), scores['fit_time'].std() * 2))\n",
    "print(\"Testing time (s):  %0.2f (+/- %0.2f)\" % (scores['score_time'].mean(), scores['score_time'].std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "Above, you should be able to make a few key observations regarding:\n",
    "\n",
    "* Accuracy\n",
    "* Training time\n",
    "\n",
    "So, it seems using scaled feature values has worked the best! But, we haven't optimised other hyper-parameters. Therefore, at this point, you could still suspend conclusions in case normalisation works well with a different configuration of the MLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search\n",
    "\n",
    "To be more confident about our observations above, this section conducts some hyper-parameter optimisation using Random Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T12:54:25.910009Z",
     "start_time": "2021-12-07T12:54:25.905986Z"
    }
   },
   "outputs": [],
   "source": [
    "# Utility function to report best scores\n",
    "def report(results, rank_metric='score', n_top=3):\n",
    "    \"\"\"\n",
    "    Utility function to report best scores.\n",
    "    :param results: the cv_results_ data structure from the optimisation algorithm\n",
    "    :param rank_metric: name of the metric to report results for\n",
    "    :param n_top: the number of top results to report\n",
    "    \"\"\"\n",
    "    print(\"\\nModels ranked according to\", rank_metric)\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results[\"rank_test_\" + rank_metric] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.2f} (+/- {1:.2f})\".format(\n",
    "                  results[\"mean_test_\" + rank_metric][candidate],\n",
    "                  results[\"std_test_\" + rank_metric][candidate]*2))\n",
    "            print(\"Params: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T12:54:25.917689Z",
     "start_time": "2021-12-07T12:54:25.911627Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "from time import time\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def random_search(model, param_dict, n_iter_search, X, y):\n",
    "    \"\"\"\n",
    "    Executing random search as part of this function in order to\n",
    "    utilise the annotation above to suppress warnings about\n",
    "    convergence (lack thereof).\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # initialise random search\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_dict,\n",
    "                                       n_iter=n_iter_search, cv=5)\n",
    "\n",
    "    # run random search\n",
    "    print(\"> STARTING RANDOM SEARCH ...\")\n",
    "    start_time = time()\n",
    "    random_search.fit(X, y)\n",
    "    end_time = time()\n",
    "\n",
    "    print(\"> RANDOM SEARCH COMPLETE\")\n",
    "\n",
    "    print(\"\\nRandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "          \" parameter settings.\" % ((end_time - start_time), n_iter_search))\n",
    "    \n",
    "    return random_search.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With normalised feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T12:54:38.792637Z",
     "start_time": "2021-12-07T12:54:25.918713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> STARTING RANDOM SEARCH ...\n",
      "> RANDOM SEARCH COMPLETE\n",
      "\n",
      "RandomizedSearchCV took 12.87 seconds for 5 candidates parameter settings.\n",
      "\n",
      "Models ranked according to score\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.92 (+/- 0.11)\n",
      "Params: {'max_iter': 3000, 'learning_rate': 'invscaling', 'hidden_layer_sizes': 40, 'activation': 'tanh'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.81 (+/- 0.43)\n",
      "Params: {'max_iter': 4500, 'learning_rate': 'invscaling', 'hidden_layer_sizes': 15, 'activation': 'tanh'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.81 (+/- 0.21)\n",
      "Params: {'max_iter': 1000, 'learning_rate': 'adaptive', 'hidden_layer_sizes': 50, 'activation': 'identity'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "# instantiating model\n",
    "model = MLPClassifier()\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dict = {\"hidden_layer_sizes\": [(5), (10), (15), (20), (30), (40), (50)],\n",
    "              \"max_iter\": [500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000],\n",
    "              \"activation\": ['identity', 'logistic', 'tanh', 'relu'],\n",
    "              \"learning_rate\": ['constant', 'invscaling', 'adaptive']}\n",
    "\n",
    "# run random search\n",
    "n_iter_search = 5 # increase this to sample even more values from the param_dict\n",
    "results = random_search(model, param_dict, n_iter_search, X_normalised, y)\n",
    "report(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With scaled feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T12:54:43.880193Z",
     "start_time": "2021-12-07T12:54:38.794469Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> STARTING RANDOM SEARCH ...\n",
      "> RANDOM SEARCH COMPLETE\n",
      "\n",
      "RandomizedSearchCV took 5.08 seconds for 5 candidates parameter settings.\n",
      "\n",
      "Models ranked according to score\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.99 (+/- 0.03)\n",
      "Params: {'max_iter': 2500, 'learning_rate': 'invscaling', 'hidden_layer_sizes': 50, 'activation': 'logistic'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.98 (+/- 0.04)\n",
      "Params: {'max_iter': 1000, 'learning_rate': 'invscaling', 'hidden_layer_sizes': 50, 'activation': 'tanh'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.98 (+/- 0.04)\n",
      "Params: {'max_iter': 3000, 'learning_rate': 'invscaling', 'hidden_layer_sizes': 15, 'activation': 'tanh'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "# instantiating model\n",
    "model = MLPClassifier()\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dict = {\"hidden_layer_sizes\": [(5), (10), (15), (20), (30), (40), (50), (60), (70), (80), (90), (100)],\n",
    "              \"max_iter\": [500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000],\n",
    "              \"activation\": ['identity', 'logistic', 'tanh', 'relu'],\n",
    "              \"learning_rate\": ['constant', 'invscaling', 'adaptive']}\n",
    "\n",
    "# run random search\n",
    "n_iter_search = 5 # increase this to sample even more values from the param_dict\n",
    "results = random_search(model, param_dict, n_iter_search, X_scaled, y)\n",
    "report(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep neural network!\n",
    "\n",
    "Ok, probably not so exciting, but the irony is that people talk about Deep Learning as something magical, and we can go from shallow to deep learning by adding 4 characters (including a space)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T12:54:44.705259Z",
     "start_time": "2021-12-07T12:54:43.882789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:          0.97 (+/- 0.05)\n",
      "Training time (s): 0.16 (+/- 0.02)\n",
      "Testing time (s):  0.00 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "epochs = 5000\n",
    "model = MLPClassifier(hidden_layer_sizes=(15, 15), max_iter=epochs)\n",
    "\n",
    "scores = cross_validate(model, X_scaled, y, cv=5)\n",
    "print(\"Accuracy:          %0.2f (+/- %0.2f)\" % (scores['test_score'].mean(), scores['test_score'].std() * 2))\n",
    "print(\"Training time (s): %0.2f (+/- %0.2f)\" % (scores['fit_time'].mean(), scores['fit_time'].std() * 2))\n",
    "print(\"Testing time (s):  %0.2f (+/- %0.2f)\" % (scores['score_time'].mean(), scores['score_time'].std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
